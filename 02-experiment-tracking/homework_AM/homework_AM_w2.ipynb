{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Week 01 | 30 May 2022\n",
    "\n",
    "The goal of this [homework](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/02-experiment-tracking/homework.md) is to get familiar with MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q1. Install MLflow\n",
    "\n",
    "For this we recommend creating a separate Python environment, for example, you can use [conda environments](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html#managing-envs), and then install the package there with `pip` or `conda`.\n",
    "\n",
    "Once you installed the package, run the command `mlflow --version` and check the output. What's the version that you have?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow, version 1.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Download and preprocess the data\n",
    "\n",
    "Use the script preprocess_data.py located in the folder homework to preprocess the data.\n",
    "\n",
    "How many files were saved to `OUTPUT_FOLDER`?\n",
    "\n",
    "4 (A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command I used in the homework_AM folder using anaconda prompt :\n",
    "\n",
    "- python preprocess_data.py --raw_data_path ./data --dest_path ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Train a model with autolog\n",
    "\n",
    "Your task is to modify the script to enable **autologging** with MLflow, execute the script and then launch the MLflow UI to check that the experiment run was properly tracked. \n",
    "\n",
    "Tip 1: don't forget to wrap the training code with a `with mlflow.start_run():` statement as we showed in the videos.\n",
    "\n",
    "Tip 2: don't modify the hyperparameters of the model to make sure that the training will finish quickly.\n",
    "\n",
    "How many parameters are automatically logged by MLflow?\n",
    "\n",
    "* 19\n",
    "* 17 (A)\n",
    "* 10\n",
    "* 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mlflow ui command that we give is only to start mlflow locally. The experiment section cane be started by just \"mlflow ui\" command. If we need to save artifacts and access the \"model\" page for **model registry**, then we have to provide a backend storage where info can be saved in one of the supported DB\n",
    "\n",
    "- Step 1: Launch mlflow UI locally using this command *mlflow ui --backend-store-uri sqlite:///mlflow.db* in the homework_AM folder. When we pass this command some folders will be created in our folder. All the information will be saved in this DB: artifacts, models, dv files etc\n",
    "\n",
    "- Step 2: Make changes in *train.py* file\n",
    "    - Set tracking URI to mlflow.db database and generate a new experiment \"nyc-green-taxi-trip\"\n",
    "    - Enable autologging\n",
    "    - Put the training code under mlflow.start_run():\n",
    "\n",
    "When we do these, we will have some folders such as mlruns, models, images, preprocessor created in our directory\n",
    "\n",
    "- Step 3: Run train.py file using command *python train.py* in the homework_AM folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Launch the tracking server locally\n",
    "\n",
    "We want to manage the entire lifecycle of our ML model. In this step, you'll need to launch a tracking server. This way we will also have access to the model registry. \n",
    "\n",
    "Your task is to\n",
    "\n",
    "* launch the tracking server on your local machine\n",
    "* select a SQLite db for the backend store and a folder called `artifacts` for the artifacts store\n",
    "\n",
    "In addition to `backend-store-uri`, what else do you need to pass to properly configure the server?\n",
    "\n",
    "* `default-artifact-root` (A)\n",
    "* `serve-artifacts`\n",
    "* `artifacts-only`\n",
    "* `artifacts-destination`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://mlflow.org/docs/0.5.1/tracking.html#tracking-server\n",
    "- https://www.mlflow.org/docs/latest/tracking.html#scenario-2-mlflow-on-localhost-with-sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q5. Tune the hyperparameters of the model - reduce the validation error\n",
    "\n",
    "Your task is to modify the script `hpo.py` and make sure that the validation RMSE is logged to MLflow for each run of the hyperparameter optimization (you will need to add a few lines of code to the `objective` function) and run the script without passing any parameters.\n",
    "\n",
    "After that, open the MLflow UI and explore the runs from the experiment called `random-forest-hyperopt` to answer the question below. Important: don't use autologging for this exercise.\n",
    "\n",
    "The idea is to just log the information that you need to answer the question below, including:\n",
    "\n",
    "* the list of hyperparameters that are passed to the `objective` function during the optimization.\n",
    "* the RMSE obtained on the validation set (February 2021 data).\n",
    "\n",
    "What's the best validation RMSE that you got?\n",
    "\n",
    "* 6.128\n",
    "* 6.628 (A)\n",
    "* 7.128\n",
    "* 7.628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Promote the best model to the model registry\n",
    "\n",
    "`register_model.py` will check the results from the previous step(validation set) and select the top 5 runs. After that, it will calculate the RMSE of those 5 models on the test set (March 2021 data) and save the results to a new experiment called `random-forest-best-models`.\n",
    "\n",
    "Update the script `register_model.py` so that it selects the model with the lowest RMSE on the test set and registers it to the model registry.\n",
    "\n",
    "Tip 1: you can use the method `search_runs` from the `MlflowClient` to get the model with the lowest RMSE.\n",
    "Tip 2: to register the model you can use the method `mlflow.register_model` and you will need to pass the right model_uri in the form of a string that looks like this: `\"runs:/<RUN_ID>/model\"`, and the name of the model (make sure to choose a good one!).\n",
    "\n",
    "What is the test RMSE of the best model?\n",
    "\n",
    "* 6.1\n",
    "* 6.55 (A)\n",
    "* 7.93\n",
    "* 15.1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6b721d063d35a739a31da4d46d142cf20b1a75373beca3d0e50133282fbfcb8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('exp-tracking-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
